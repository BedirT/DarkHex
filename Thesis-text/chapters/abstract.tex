\thispagestyle{acknowledgements}
\section*{Abstract}
\addcontentsline{toc}{section}{Abstract}

Dark-Hex is the imperfect information version of the game Hex. In this work, we have examined 
the game's interesting properties and provided the solution to some of the small board sizes.
We were mainly interested in an approximate solution and a definitive player. We got Nash solution 
on small boards using pure strategy LP on different game modes.
This allowed us to explore and analyze the properties of the different versions of the games 
we describe here.
Next, we evaluated Sequence-LP on different board sizes, the results showed that for bigger 
board sizes we needed more approximate solutions.
For the last part of our evaluation, we worked with the well-known algorithm for partial 
information environments; Counterfactual Regret Minimization. We did analyze vanilla CFR 
alongside evolved versions of it, RCFR, f-RCFR. We lastly present an increment to f-RCFR 
<appendName> ... <appendDifferences>. The end of the thesis is our player. We developed a 
state-of-the-art player \textbf{(not sure if we can call it state of the art as there is 
no player exist for the domain at the moment)}. 
In this chapter, we have trained some classical Reinforcement 
Learning players, vanilla CFR, RCFR, f-RCFR, <appendName> and some other popular algorithms 
\textbf{(Should include some combination etc. as well, I cannot name what exactly as I need 
to work on them before saying anything)}. We got the benchmark by setting a league-like system 
and constantly competing with the players.
Our player <appendName> got the top place \textbf{like this...}.

